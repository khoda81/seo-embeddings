{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55139403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "logger = logging.getLogger(\"Notebook\")\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23cfa2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "DATASET_PATH = pathlib.Path(\n",
    "    \"dataset/annotated/project-1-at-2025-11-15-15-33-207ebb0e.json\"\n",
    ")\n",
    "\n",
    "with open(DATASET_PATH, \"r\") as f:\n",
    "    dataset_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1bff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task 2153 has more than one annotation, selecting the last\n",
      "Task 2223 has more than one annotation, selecting the last\n",
      "Task 2277 has more than one annotation, selecting the last\n",
      "Task 2677 has more than one annotation, selecting the last\n",
      "Task 3025 has more than one annotation, selecting the last\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tasks: 969\n",
      "Sample: {'query': 'Ú©ÙˆØ±', 'negatives': ['kor', 'korkar', 'kor eng', 'Ú©ÙˆØ±ØªÛŒ', 'korrea', 'ÙƒÙˆØ±Ø¯', 'Ú©ÙˆÛŒØ±', 'korosh'], 'positives': ['Ú©ÙˆØ±', 'Ù…ÙˆØ´ Ú©ÙˆØ±']}\n"
     ]
    }
   ],
   "source": [
    "def task_to_datapoint(task: dict) -> dict | None:\n",
    "    \"\"\"\n",
    "    Convert Label Studio ranking dataset â†’ canonical format:\n",
    "    [\n",
    "        {\n",
    "            \"query\": str,\n",
    "            \"negatives\": [str, ...],\n",
    "            \"positives\": [str, ...]\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# ---- Load dataset ----\n",
    "dataset = []\n",
    "for task in dataset_json:\n",
    "    datapoint = task_to_datapoint(task)\n",
    "\n",
    "    # --- extract query ---\n",
    "    data = task[\"data\"]\n",
    "    query = data[\"query\"]\n",
    "\n",
    "    # --- extract candidate options ---\n",
    "    # some items have only score + value; we keep only value\n",
    "    candidates = [opt[\"value\"] for opt in data[\"options\"]]\n",
    "\n",
    "    annotations = [\n",
    "        annotation\n",
    "        for annotation in task[\"annotations\"]\n",
    "        if not annotation[\"was_cancelled\"]\n",
    "    ]\n",
    "\n",
    "    if not annotations:\n",
    "        continue\n",
    "\n",
    "    if 1 < len(annotations):\n",
    "        logger.warning(\n",
    "            \"Task %s has more than one annotation, selecting the last\", task[\"id\"]\n",
    "        )\n",
    "\n",
    "    for res in annotations[-1][\"result\"]:\n",
    "        if res[\"from_name\"] != \"rel\":\n",
    "            continue\n",
    "\n",
    "        # LabelStudio \"choices\" format\n",
    "        positives = res[\"value\"][\"choices\"]\n",
    "        negatives = [n for n in candidates if n not in positives]\n",
    "\n",
    "        dataset.append({\"query\": query, \"negatives\": negatives, \"positives\": positives})\n",
    "        break\n",
    "\n",
    "    continue\n",
    "\n",
    "\n",
    "print(\"Loaded tasks:\", len(dataset))\n",
    "print(\"Sample:\", dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59941486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence1', 'sentence2', 'label'],\n",
      "    num_rows: 9690\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def expand_rows(rows):\n",
    "    s1, s2, labels = [], [], []\n",
    "    for row in rows:\n",
    "        q = row[\"query\"]\n",
    "        for p in row[\"positives\"]:\n",
    "            s1.append(q)\n",
    "            s2.append(p)\n",
    "            labels.append(1)\n",
    "\n",
    "        for n in row[\"negatives\"]:\n",
    "            s1.append(q)\n",
    "            s2.append(n)\n",
    "            labels.append(0)\n",
    "\n",
    "    return {\"sentence1\": s1, \"sentence2\": s2, \"label\": labels}\n",
    "\n",
    "\n",
    "expanded = expand_rows(dataset)\n",
    "hf_dataset = Dataset.from_dict(expanded)\n",
    "\n",
    "print(hf_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5d3cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = Dataset.load_from_disk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset.sav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66756b88",
   "metadata": {},
   "source": [
    "### Model + LoRA (PEFT) setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe522b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    InputExample,\n",
    "    losses,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    ")\n",
    "\n",
    "# 1) Load base Persian model\n",
    "model = SentenceTransformer(\"xmanii/maux-gte-persian-v3\", allow_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8044d7ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m.named_modules()\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    losses,\n",
    "    util,\n",
    ")\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"xmanii/maux-gte-persian-v3\")\n",
    "\n",
    "loss = losses.OnlineContrastiveLoss(\n",
    "    model=model,\n",
    "    # default metric = 1 - cos_sim. Good for embedding.\n",
    "    margin=0.5,\n",
    ")\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"/kaggle/working/gte-persian-seo\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=32,  # adjust to VRAM; increase via grad_accum\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.05,\n",
    "    # fp16=True,\n",
    "    logging_steps=50,\n",
    "    save_steps=1000,\n",
    "    run_name=\"gte-persian-seo\",\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    train_dataset=hf_dataset,\n",
    "    loss=loss,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152ed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5825ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    losses,\n",
    "    util,\n",
    ")\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"xmanii/maux-gte-persian-v3\", trust_remote_code=True)\n",
    "\n",
    "loss = losses.OnlineContrastiveLoss(\n",
    "    model=model,\n",
    "    # default metric = 1 - cos_sim. Good for embedding.\n",
    "    margin=0.5,\n",
    ")\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"/kaggle/working/gte-persian-seo\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=32,  # adjust to VRAM; increase via grad_accum\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.05,\n",
    "    # fp16=True,\n",
    "    logging_steps=50,\n",
    "    save_steps=1000,\n",
    "    run_name=\"gte-persian-seo\",\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    train_dataset=hf_dataset,\n",
    "    loss=loss,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56043456",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fad4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "\n",
    "# 2) Add a LoRA adapter\n",
    "lora = LoraConfig(\n",
    "    task_type=TaskType.FEATURE_EXTRACTION,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    ")\n",
    "model.add_adapter(lora)  # SBERT integrates with PEFT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download from the ðŸ¤— Hub\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "# Run inference\n",
    "sentences = [\n",
    "    \"is toprol xl the same as metoprolol?\",\n",
    "    \"Metoprolol succinate is also known by the brand name Toprol XL. It is the extended-release form of metoprolol. Metoprolol succinate is approved to treat high blood pressure, chronic chest pain, and congestive heart failure.\",\n",
    "    \"Metoprolol starts to work after about 2 hours, but it can take up to 1 week to fully take effect. You may not feel any different when you take metoprolol, but this doesn't mean it's not working. It's important to keep taking your medicine\",\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "# [3, 768]\n",
    "\n",
    "# Get the similarity scores for the embeddings\n",
    "similarities = model.similarity(embeddings[0], embeddings[1:])\n",
    "print(similarities)\n",
    "# tensor([[0.7913, 0.4976]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6112b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# model.encode()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m.prompts\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.encode()\n",
    "# model.prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4011d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_to_datapoint(tasks[9])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
