{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a395699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clickhouse_connect\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# qdrant_client = QdrantClient(\"http://127.0.0.1:6333\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ch_client = clickhouse_connect.get_client(\n",
    "    host=os.getenv(\"CLICKHOUSE_HOST\"),\n",
    "    port=int(os.getenv(\"CLICKHOUSE_PORT\")),\n",
    "    username=os.getenv(\"CLICKHOUSE_USERNAME\"),\n",
    "    password=os.getenv(\"CLICKHOUSE_PASSWORD\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf4e6180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing clickhouse with a simple query...\n",
      "Test query result:\n",
      "%s   keyword  q.similarity website  average_position\n",
      "0      hi           0.9                       0.0\n",
      "1     buy           0.8                       0.0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print(\"Testing clickhouse with a simple query...\")\n",
    "query_ranks = Path(\"queries/website_by_keyword.sql\").read_text(encoding=\"utf-8\")\n",
    "df = ch_client.query_df(\n",
    "    query_ranks, parameters={\"keywords\": [\"hi\", \"buy\"], \"similarity\": [0.9, 0.8]}\n",
    ")\n",
    "print(\"Test query result:\\n%s\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "839a8400",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EMBEDDING_MODEL_PATH\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01memcache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OllamaBackend\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01memseo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstorage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VectorStoreEmbedding\n\u001b[32m      5\u001b[39m backend = OllamaBackend(base_url=\u001b[33m\"\u001b[39m\u001b[33mhttp://127.0.0.1:11434\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\seo_embeddings\\src\\emcache\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01memcache\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseCachedEmbedding\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01memcache\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhuggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceBackend\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01memcache\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OllamaBackend\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Projects\\seo_embeddings\\src\\emcache\\base.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Protocol, runtime_checkable\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mattrs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[32m      8\u001b[39m \u001b[38;5;129m@runtime_checkable\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mEmbeddingBackend\u001b[39;00m(Protocol):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20mah\\anaconda3\\envs\\rl\\Lib\\site-packages\\torch\\__init__.py:2150\u001b[39m\n\u001b[32m   2143\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _disable_dynamo  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2145\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2146\u001b[39m \u001b[38;5;66;03m# Import interface functions defined in Python\u001b[39;00m\n\u001b[32m   2147\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2148\u001b[39m \n\u001b[32m   2149\u001b[39m \u001b[38;5;66;03m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2150\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF \u001b[38;5;28;01mas\u001b[39;00m _VF, functional \u001b[38;5;28;01mas\u001b[39;00m functional  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2151\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[32m   2153\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2154\u001b[39m \u001b[38;5;66;03m# Remove unnecessary members\u001b[39;00m\n\u001b[32m   2155\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20mah\\anaconda3\\envs\\rl\\Lib\\site-packages\\torch\\functional.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Optional, TYPE_CHECKING, Union\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF, Tensor\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _add_docstr\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20mah\\anaconda3\\envs\\rl\\Lib\\site-packages\\torch\\nn\\__init__.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      3\u001b[39m     Buffer \u001b[38;5;28;01mas\u001b[39;00m Buffer,\n\u001b[32m      4\u001b[39m     Parameter \u001b[38;5;28;01mas\u001b[39;00m Parameter,\n\u001b[32m      5\u001b[39m     UninitializedBuffer \u001b[38;5;28;01mas\u001b[39;00m UninitializedBuffer,\n\u001b[32m      6\u001b[39m     UninitializedParameter \u001b[38;5;28;01mas\u001b[39;00m UninitializedParameter,\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     attention \u001b[38;5;28;01mas\u001b[39;00m attention,\n\u001b[32m     11\u001b[39m     functional \u001b[38;5;28;01mas\u001b[39;00m functional,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataParallel \u001b[38;5;28;01mas\u001b[39;00m DataParallel\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20mah\\anaconda3\\envs\\rl\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Module  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bilinear, Identity, LazyLinear, Linear  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     CELU,\n\u001b[32m      5\u001b[39m     ELU,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     Threshold,\n\u001b[32m     33\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20mah\\anaconda3\\envs\\rl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_prims_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeviceLikeType\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Buffer, Parameter\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_traceable_wrapper_subclass\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackwardHook, RemovableHandle\n\u001b[32m     21\u001b[39m __all__ = [\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mregister_module_forward_pre_hook\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mregister_module_forward_hook\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mModule\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     31\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20mah\\anaconda3\\envs\\rl\\Lib\\site-packages\\torch\\utils\\__init__.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mweakref\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     backcompat \u001b[38;5;28;01mas\u001b[39;00m backcompat,\n\u001b[32m     10\u001b[39m     collect_env \u001b[38;5;28;01mas\u001b[39;00m collect_env,\n\u001b[32m     11\u001b[39m     data \u001b[38;5;28;01mas\u001b[39;00m data,\n\u001b[32m     12\u001b[39m     deterministic \u001b[38;5;28;01mas\u001b[39;00m deterministic,\n\u001b[32m     13\u001b[39m     hooks \u001b[38;5;28;01mas\u001b[39;00m hooks,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_registration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     generate_methods_for_privateuse1_backend,\n\u001b[32m     17\u001b[39m     rename_privateuse1_backend,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpp_backtrace\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_cpp_backtrace\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20mah\\anaconda3\\envs\\rl\\Lib\\site-packages\\torch\\utils\\data\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     _DatasetKind,\n\u001b[32m      3\u001b[39m     DataLoader,\n\u001b[32m      4\u001b[39m     default_collate,\n\u001b[32m      5\u001b[39m     default_convert,\n\u001b[32m      6\u001b[39m     get_worker_info,\n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatapipes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_decorator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     argument_validation,\n\u001b[32m     10\u001b[39m     functional_datapipe,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     runtime_validation_disabled,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatapipes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     17\u001b[39m     DataChunk,\n\u001b[32m     18\u001b[39m     DFIterDataPipe,\n\u001b[32m     19\u001b[39m     IterDataPipe,\n\u001b[32m     20\u001b[39m     MapDataPipe,\n\u001b[32m     21\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20mah\\anaconda3\\envs\\rl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdist\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_settings\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExceptionWrapper\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _utils\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20mah\\anaconda3\\envs\\rl\\Lib\\site-packages\\torch\\utils\\data\\graph_settings.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatapipes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01miter\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msharding\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     _ShardingIterDataPipe,\n\u001b[32m     10\u001b[39m     SHARDING_PRIORITIES,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataPipe, DataPipeGraph, traverse_dps\n\u001b[32m     15\u001b[39m __all__ = [\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mapply_random_seed\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mapply_sharding\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mget_all_graph_pipes\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20mah\\anaconda3\\envs\\rl\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatapipes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataframe \u001b[38;5;28;01mas\u001b[39;00m dataframe, \u001b[38;5;28miter\u001b[39m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;28miter\u001b[39m, \u001b[38;5;28mmap\u001b[39m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;28mmap\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20mah\\anaconda3\\envs\\rl\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatapipes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01miter\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     CollatorIterDataPipe \u001b[38;5;28;01mas\u001b[39;00m Collator,\n\u001b[32m      3\u001b[39m     MapperIterDataPipe \u001b[38;5;28;01mas\u001b[39;00m Mapper,\n\u001b[32m      4\u001b[39m )\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatapipes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01miter\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcombinatorics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     SamplerIterDataPipe \u001b[38;5;28;01mas\u001b[39;00m Sampler,\n\u001b[32m      7\u001b[39m     ShufflerIterDataPipe \u001b[38;5;28;01mas\u001b[39;00m Shuffler,\n\u001b[32m      8\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatapipes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01miter\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcombining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     ConcaterIterDataPipe \u001b[38;5;28;01mas\u001b[39;00m Concater,\n\u001b[32m     11\u001b[39m     DemultiplexerIterDataPipe \u001b[38;5;28;01mas\u001b[39;00m Demultiplexer,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     ZipperIterDataPipe \u001b[38;5;28;01mas\u001b[39;00m Zipper,\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\20mah\\anaconda3\\envs\\rl\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\callable.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Iterator, Sized\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Optional, TypeVar, Union\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_utils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcollate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m default_collate\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatapipes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_decorator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional_datapipe\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatapipes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataframe_wrapper \u001b[38;5;28;01mas\u001b[39;00m df_wrapper\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:991\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1087\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1186\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from config import EMBEDDING_MODEL_PATH\n",
    "from emcache import OllamaBackend\n",
    "from emseo.storage import VectorStoreEmbedding\n",
    "\n",
    "backend = OllamaBackend(base_url=\"http://127.0.0.1:11434\")\n",
    "storage = VectorStoreEmbedding(backend, collection_prefix=\"keywords\")\n",
    "# storage.embedder.load_state_dict(\n",
    "#     torch.load(EMBEDDING_MODEL_PATH / f\"{storage.collection_name}.pt\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a40831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/fastapi/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from emcache.huggingface import HuggingFaceBackend\n",
    "from emseo.storage import VectorStoreEmbedding\n",
    "\n",
    "\n",
    "# Initialize\n",
    "# backend = HuggingFaceBackend(model_name=\"heydariAI/persian-embeddings\")\n",
    "backend = HuggingFaceBackend(model_name=\"intfloat/multilingual-e5-large\")\n",
    "storage = VectorStoreEmbedding(backend, collection_prefix=\"keywords\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c1f6d",
   "metadata": {},
   "source": [
    "### Initialize Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e101e3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding www.tourismonline.com:   0%|          | 0/101 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding ana.ir:   3%|â–Ž         | 3/101 [05:49<3:10:28, 116.62s/it]            \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m keywords = website_keywords[\u001b[33m\"\u001b[39m\u001b[33mkeyword\u001b[39m\u001b[33m\"\u001b[39m].tolist()\n\u001b[32m     21\u001b[39m website_pbar.set_description(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbedding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwebsite\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m keyword_embedding = \u001b[43mstorage\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedder\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m.embedding\n\u001b[32m     23\u001b[39m average_position = website_keywords[\u001b[33m\"\u001b[39m\u001b[33maverage_position\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     25\u001b[39m weights = \u001b[32m1\u001b[39m / torch.tensor(average_position.array).unsqueeze(-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/fastapi/seo-embeddings/src/emcache/base.py:61\u001b[39m, in \u001b[36mBaseCachedEmbedding.embed\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m     58\u001b[39m new_texts = [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m texts \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embed_keys]\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_texts:\n\u001b[32m     60\u001b[39m     new_embs = torch.tensor(\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_texts\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     62\u001b[39m         device=\u001b[38;5;28mself\u001b[39m.embed_cache.device,\n\u001b[32m     63\u001b[39m         dtype=\u001b[38;5;28mself\u001b[39m.embed_cache.dtype,\n\u001b[32m     64\u001b[39m     )\n\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# expand cache\u001b[39;00m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28mself\u001b[39m.embed_cache.data = torch.cat([\u001b[38;5;28mself\u001b[39m.embed_cache.data, new_embs], dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/fastapi/seo-embeddings/src/emcache/huggingface.py:13\u001b[39m, in \u001b[36mHuggingFaceBackend.embed_texts\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_texts\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m.tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1094\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m features.update(extra_features)\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/sentence_transformers/models/Transformer.py:261\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[32m    240\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    257\u001b[39m \u001b[33;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    259\u001b[39m trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    263\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:853\u001b[39m, in \u001b[36mXLMRobertaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    846\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    847\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    848\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    849\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    850\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    851\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m--> \u001b[39m\u001b[32m853\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    867\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:607\u001b[39m, in \u001b[36mXLMRobertaEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    603\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m    605\u001b[39m layer_head_mask = head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m607\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    612\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    618\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    619\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:514\u001b[39m, in \u001b[36mXLMRobertaLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    504\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    512\u001b[39m     cache_position: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    513\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m514\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    522\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    523\u001b[39m     outputs = self_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:441\u001b[39m, in \u001b[36mXLMRobertaAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    430\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    432\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    439\u001b[39m     cache_position: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    440\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m     self_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    450\u001b[39m     attention_output = \u001b[38;5;28mself\u001b[39m.output(self_outputs[\u001b[32m0\u001b[39m], hidden_states)\n\u001b[32m    451\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:314\u001b[39m, in \u001b[36mXLMRobertaSdpaSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().forward(\n\u001b[32m    302\u001b[39m         hidden_states,\n\u001b[32m    303\u001b[39m         attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    308\u001b[39m         cache_position,\n\u001b[32m    309\u001b[39m     )\n\u001b[32m    311\u001b[39m bsz, tgt_len, _ = hidden_states.size()\n\u001b[32m    313\u001b[39m query_layer = (\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m.view(bsz, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_attention_heads, \u001b[38;5;28mself\u001b[39m.attention_head_size).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    315\u001b[39m )\n\u001b[32m    317\u001b[39m is_updated = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    318\u001b[39m is_cross_attention = encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/fastapi/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import uuid\n",
    "import torch\n",
    "import tqdm.auto as tqdm\n",
    "from qdrant_client.http.models import PointStruct\n",
    "\n",
    "chunk_size = 128\n",
    "query_websites = Path(\"queries/website_list.sql\").read_text(encoding=\"utf-8\")\n",
    "query_keywords = Path(\"queries/keywords_by_website.sql\").read_text(encoding=\"utf-8\")\n",
    "websites = ch_client.query_df(query_websites)\n",
    "\n",
    "website_pbar = tqdm.tqdm(websites[\"website\"], desc=\"Websites\")\n",
    "for website in website_pbar:\n",
    "    website_pbar.set_description(f\"Reading {website}\")\n",
    "\n",
    "    website_keywords = ch_client.query_df(\n",
    "        query_keywords, parameters={\"website\": website}\n",
    "    )\n",
    "\n",
    "    keywords = website_keywords[\"keyword\"].tolist()\n",
    "    website_pbar.set_description(f\"Embedding {website}\")\n",
    "    keyword_embedding = storage.embedder.embed(keywords).embedding\n",
    "    average_position = website_keywords[\"average_position\"]\n",
    "\n",
    "    weights = 1 / torch.tensor(average_position.array).unsqueeze(-1)\n",
    "    weighted_embeddings = weights * keyword_embedding\n",
    "\n",
    "    # Normalize the average\n",
    "    website_embedding = weighted_embeddings.mean(dim=0)\n",
    "    website_embedding = website_embedding / website_embedding.norm()\n",
    "\n",
    "    # website_point = PointStruct(\n",
    "    #     id=uuid.uuid5(uuid.NAMESPACE_URL, website).hex,\n",
    "    #     vector=website_embedding.tolist(),\n",
    "    #     payload={\"website\": website},\n",
    "    # )\n",
    "\n",
    "    # storage.add_points([website_point])\n",
    "    website_pbar.set_description(f\"Inserting {website}\")\n",
    "    # continue\n",
    "\n",
    "    insertion_pbar = tqdm.tqdm(\n",
    "        total=len(website_keywords),\n",
    "        desc=\"Adding keywords\",\n",
    "        leave=False,\n",
    "    )\n",
    "\n",
    "    # Create a new column filled with the website name\n",
    "    # website_keywords[\"website\"] = website\n",
    "\n",
    "    # payloads = website_keywords.to_dict(orient=\"records\")\n",
    "    # This can be sped up using upload collection\n",
    "    for i in range(0, len(website_keywords), chunk_size):\n",
    "        keywords = website_keywords[\"keyword\"].tolist()[i : i + chunk_size]\n",
    "        storage.add_texts(\n",
    "            texts=keywords,\n",
    "            # payloads=payloads[i : i + chunk_size],\n",
    "        )\n",
    "        insertion_pbar.update(len(keywords))\n",
    "\n",
    "    insertion_pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6ad43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20mah\\anaconda3\\envs\\rl\\Lib\\site-packages\\jupyternotify\\jupyternotify.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    },
    {
     "data": {
      "application/javascript": "if (!(\"Notification\" in window)) {\n    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n    Notification.requestPermission(function (permission) {\n        if(!('permission' in Notification)) {\n            Notification.permission = permission;\n        }\n    })\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b98b0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "$(document).ready(\n    function() {\n        function appendUniqueDiv(){\n            // append a div with our uuid so we can check that it's already\n            // been sent and avoid duplicates on page reload\n            var notifiedDiv = document.createElement(\"div\")\n            notifiedDiv.id = \"6ebcf8b9-af72-4c13-9f4e-88abd719fac5\"\n            element.append(notifiedDiv)\n        }\n\n        // only send notifications if the pageload is complete; this will\n        // help stop extra notifications when a saved notebook is loaded,\n        // which during testing gives us state \"interactive\", not \"complete\"\n        if (document.readyState === 'complete') {\n            // check for the div that signifies that the notification\n            // was already sent\n            if (document.getElementById(\"6ebcf8b9-af72-4c13-9f4e-88abd719fac5\") === null) {\n                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n                if (Notification.permission !== 'denied') {\n                    if (Notification.permission !== 'granted') { \n                        Notification.requestPermission(function (permission) {\n                            if(!('permission' in Notification)) {\n                                Notification.permission = permission\n                            }\n                        })\n                    }\n                    if (Notification.permission === 'granted') {\n                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n                    appendUniqueDiv()\n                    notification.onclick = function () {\n                        window.focus();\n                        this.close();\n                        };\n                    } \n                }     \n            }\n        }\n    }\n)\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17332caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93178"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.info().points_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "292d3fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "website\n",
       "www.khordad.news          0.932091\n",
       "www.bartarinha.ir         0.932091\n",
       "www.tgju.org              0.775526\n",
       "www.eghtesadonline.com    0.474597\n",
       "www.fardanews.com         0.474286\n",
       "digiato.com               0.348328\n",
       "www.sharghdaily.com       0.250882\n",
       "www.zoomit.ir             0.200367\n",
       "arzdigital.com            0.185799\n",
       "asemooni.com              0.167371\n",
       "www.iranjib.ir            0.144222\n",
       "tejaratnews.com           0.106377\n",
       "fararu.com                0.082409\n",
       "www.khabaronline.ir       0.072079\n",
       "www.asriran.com           0.065927\n",
       "www.tabnak.ir             0.054939\n",
       "www.irna.ir               0.038574\n",
       "carap.ir                  0.027179\n",
       "ana.ir                    0.018826\n",
       "talaangor.ir              0.018073\n",
       "Name: score, dtype: float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# Query\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "results = storage.search(query=\"Ø®Ø±ÛŒØ¯ \", top_k=32)\n",
    "\n",
    "\n",
    "result = []\n",
    "websites = []\n",
    "for r in results.points:\n",
    "    # related_keywords.append(r.payload[\"text\"])\n",
    "    # if \"keyword\" not in r.payload:\n",
    "    #     # print(f\"{r.score:<.4f} -> {r.payload['website']}\")\n",
    "    #     websites.append({\"website\": r.payload[\"website\"], \"similarity\": r.score})\n",
    "\n",
    "    if \"text\" in r.payload:\n",
    "        # print(\n",
    "        #     f\"{r.score:<.4f} $ {r.payload['average_position']:>6.2f} | {r.payload['keyword']} -> {r.payload['website']}\"\n",
    "        # )\n",
    "\n",
    "        result.append(\n",
    "            {\n",
    "                \"similarity\": r.score,\n",
    "                # \"average_position\": r.payload[\"average_position\"],\n",
    "                # \"website\": r.payload[\"website\"],\n",
    "                \"keyword\": r.payload[\"text\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # print(f\"{r.score:<.4f} | {r.payload}\")\n",
    "\n",
    "result = pd.DataFrame(result)\n",
    "websites = pd.DataFrame(websites)\n",
    "# result\n",
    "# websites\n",
    "\n",
    "query_ranks = Path(\"queries/website_by_keyword.sql\").read_text(encoding=\"utf-8\")\n",
    "\n",
    "ranks = ch_client.query_df(\n",
    "    query_ranks,\n",
    "    parameters={\n",
    "        \"keywords\": result[\"keyword\"].tolist(),\n",
    "        \"similarity\": result[\"similarity\"].tolist(),\n",
    "    },\n",
    ").rename(columns={\"q.similarity\": \"similarity\"})\n",
    "\n",
    "\n",
    "ranks[\"score\"] = (\n",
    "    ranks[\"similarity\"] / ranks[\"average_position\"]\n",
    ")  # np.log(ranks[\"average_position\"] + 1)\n",
    "ranked_websites = ranks.groupby(\"website\")[\"score\"].mean().sort_values(ascending=False)\n",
    "ranked_websites.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "08a15aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>average_position</th>\n",
       "      <th>website</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.957000</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ù„Ù¾ ØªØ§Ù¾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.952356</td>\n",
       "      <td>5.285714</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ù„Ù¾ØªØ§Ù¾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.938953</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ ØªØ¨Ù„Øª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.922697</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ù„Ø¨ ØªØ§Ù¾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.921730</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ù…ÙˆØ¨Ø§ÛŒÙ„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.921361</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ù„Ø¨ ØªØ§Ø¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.918930</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ù‚ÛŒÙ…Øª Ù„Ù¾ ØªØ§Ù¾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.910160</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø®Ø±ÛŒØ¯ Ù„Ù¾ ØªØ§Ù¾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.910124</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ú¯ÙˆØ´ÛŒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.909331</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ù„Ù¾ ØªØ§Ø¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.905541</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ ØªÙ„ÙˆÛŒØ²ÛŒÙˆÙ†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.902648</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>zoomtech.org</td>\n",
       "      <td>Ù‚ÛŒÙ…Øª Ù„Ù¾ ØªØ§Ù¾ Ù„Ù†ÙˆÙˆ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.898987</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>ana.ir</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ù†Ù‚Ø§Ø¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.898119</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>www.gsm.ir</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ø§ÛŒØ±Ù¾Ø§Ø¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.898040</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>www.55online.news</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ø¯Ù…Ø¨Ù„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.897724</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ù…Ø§Ù†ÛŒØªÙˆØ±</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.897595</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>cryptonegar.com</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ù„Ø¬Ø±</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.897093</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>zoomtech.org</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ù‡Ø¯ÙÙˆÙ†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.896636</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>arzdigital.com</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ ØªØªØ±</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.896491</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>ana.ir</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ø§Ø² Ø¹Ù„ÛŒ Ø¨Ø§Ø¨Ø§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.896471</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>www.fardanews.com</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ù„Ø§Ù…Ø§Ø±ÛŒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.896090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ø¨Ù‡ØªØ±ÛŒÙ† Ù„Ù¾ ØªØ§Ù¾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.896020</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>arzdigital.com</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ù„Ø§ÛŒØª Ú©ÙˆÛŒÙ†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.895786</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ù„Ù¾ ØªØ§Ù¾ Ù„Ù†ÙˆÙˆ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.895616</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>arzdigital.com</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ ØªØ±ÙˆÙ†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.895590</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>fararu.com</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ø³ÛŒ Ù¾ÛŒ Ú©Ø§Ù„Ø§Ù</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.895538</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>arzdigital.com</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ø±ÛŒÙ¾Ù„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.894727</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>www.sharghdaily.com</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.894038</td>\n",
       "      <td>3.523809</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>Ù„Ù¾ ØªØ§Ù¾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.893851</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>zoomtech.org</td>\n",
       "      <td>Ù‚ÛŒÙ…Øª Ù„Ù¾ ØªØ§Ù¾ Ø§Ù¾Ù„</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.893147</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>www.iranjib.ir</td>\n",
       "      <td>Ù‚ÛŒÙ…Øª Ø±ÙˆØ² Ù„Ù¾ ØªØ§Ù¾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.892563</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>mihanblockchain.com</td>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ø¨ÛŒØª Ú©ÙˆÛŒÙ†</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    similarity  average_position              website              keyword\n",
       "0     0.957000          5.222222        www.zoomit.ir          Ø®Ø±ÛŒØ¯ Ù„Ù¾ ØªØ§Ù¾\n",
       "1     0.952356          5.285714        www.zoomit.ir           Ø®Ø±ÛŒØ¯ Ù„Ù¾ØªØ§Ù¾\n",
       "2     0.938953          4.200000        www.zoomit.ir            Ø®Ø±ÛŒØ¯ ØªØ¨Ù„Øª\n",
       "3     0.922697          3.111111        www.zoomit.ir               Ù„Ø¨ ØªØ§Ù¾\n",
       "4     0.921730          5.125000        www.zoomit.ir          Ø®Ø±ÛŒØ¯ Ù…ÙˆØ¨Ø§ÛŒÙ„\n",
       "5     0.921361          3.625000        www.zoomit.ir               Ù„Ø¨ ØªØ§Ø¨\n",
       "6     0.918930          3.750000        www.zoomit.ir          Ù‚ÛŒÙ…Øª Ù„Ù¾ ØªØ§Ù¾\n",
       "7     0.910160          1.000000        www.zoomit.ir  Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø®Ø±ÛŒØ¯ Ù„Ù¾ ØªØ§Ù¾\n",
       "8     0.910124          5.200000        www.zoomit.ir            Ø®Ø±ÛŒØ¯ Ú¯ÙˆØ´ÛŒ\n",
       "9     0.909331          3.400000        www.zoomit.ir               Ù„Ù¾ ØªØ§Ø¨\n",
       "10    0.905541          3.166667        www.zoomit.ir        Ø®Ø±ÛŒØ¯ ØªÙ„ÙˆÛŒØ²ÛŒÙˆÙ†\n",
       "11    0.902648         83.000000         zoomtech.org     Ù‚ÛŒÙ…Øª Ù„Ù¾ ØªØ§Ù¾ Ù„Ù†ÙˆÙˆ\n",
       "12    0.898987         18.000000               ana.ir            Ø®Ø±ÛŒØ¯ Ù†Ù‚Ø§Ø¨\n",
       "13    0.898119         98.500000           www.gsm.ir          Ø®Ø±ÛŒØ¯ Ø§ÛŒØ±Ù¾Ø§Ø¯\n",
       "14    0.898040         69.000000    www.55online.news            Ø®Ø±ÛŒØ¯ Ø¯Ù…Ø¨Ù„\n",
       "15    0.897724          6.833333        www.zoomit.ir         Ø®Ø±ÛŒØ¯ Ù…Ø§Ù†ÛŒØªÙˆØ±\n",
       "16    0.897595         76.000000      cryptonegar.com             Ø®Ø±ÛŒØ¯ Ù„Ø¬Ø±\n",
       "17    0.897093         78.000000         zoomtech.org           Ø®Ø±ÛŒØ¯ Ù‡Ø¯ÙÙˆÙ†\n",
       "18    0.896636         10.888889       arzdigital.com             Ø®Ø±ÛŒØ¯ ØªØªØ±\n",
       "19    0.896491         61.000000               ana.ir     Ø®Ø±ÛŒØ¯ Ø§Ø² Ø¹Ù„ÛŒ Ø¨Ø§Ø¨Ø§\n",
       "20    0.896471         65.000000    www.fardanews.com          Ø®Ø±ÛŒØ¯ Ù„Ø§Ù…Ø§Ø±ÛŒ\n",
       "21    0.896090          1.000000        www.zoomit.ir        Ø¨Ù‡ØªØ±ÛŒÙ† Ù„Ù¾ ØªØ§Ù¾\n",
       "22    0.896020          6.000000       arzdigital.com       Ø®Ø±ÛŒØ¯ Ù„Ø§ÛŒØª Ú©ÙˆÛŒÙ†\n",
       "23    0.895786          4.375000        www.zoomit.ir          Ù„Ù¾ ØªØ§Ù¾ Ù„Ù†ÙˆÙˆ\n",
       "24    0.895616         10.333333       arzdigital.com            Ø®Ø±ÛŒØ¯ ØªØ±ÙˆÙ†\n",
       "25    0.895590          8.000000           fararu.com     Ø®Ø±ÛŒØ¯ Ø³ÛŒ Ù¾ÛŒ Ú©Ø§Ù„Ø§Ù\n",
       "26    0.895538          4.000000       arzdigital.com            Ø®Ø±ÛŒØ¯ Ø±ÛŒÙ¾Ù„\n",
       "27    0.894727         45.000000  www.sharghdaily.com                 Ø®Ø±ÛŒØ¯\n",
       "28    0.894038          3.523809        www.zoomit.ir               Ù„Ù¾ ØªØ§Ù¾\n",
       "29    0.893851         84.000000         zoomtech.org      Ù‚ÛŒÙ…Øª Ù„Ù¾ ØªØ§Ù¾ Ø§Ù¾Ù„\n",
       "30    0.893147          8.000000       www.iranjib.ir      Ù‚ÛŒÙ…Øª Ø±ÙˆØ² Ù„Ù¾ ØªØ§Ù¾\n",
       "31    0.892563         83.000000  mihanblockchain.com        Ø®Ø±ÛŒØ¯ Ø¨ÛŒØª Ú©ÙˆÛŒÙ†"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4c12979b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "website\n",
       "arzdigital.com            0.690105\n",
       "www.tgju.org              0.583497\n",
       "www.iranjib.ir            0.320383\n",
       "www.shomanews.com         0.221259\n",
       "tejaratnews.com           0.178851\n",
       "www.sharghdaily.com       0.155436\n",
       "www.entekhab.ir           0.154838\n",
       "diginoy.com               0.127491\n",
       "mihanblockchain.com       0.117071\n",
       "www.iscanews.ir           0.115437\n",
       "www.eghtesadonline.com    0.104757\n",
       "www.etemadonline.com      0.075478\n",
       "www.tasnimnews.com        0.059003\n",
       "donya-e-eqtesad.com       0.053102\n",
       "www.parsine.com           0.017386\n",
       "iraneconomist.com         0.014681\n",
       "aftabnews.ir              0.014344\n",
       "mihansignal.com           0.014311\n",
       "utofx.com                 0.012829\n",
       "www.hamyarcrypto.com      0.012355\n",
       "Name: score, dtype: float32"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "ranks[\"score\"] = (\n",
    "    ranks[\"similarity\"] / ranks[\"average_position\"]\n",
    ")  # np.log(ranks[\"average_position\"] + 1)\n",
    "ranked_websites = ranks.groupby(\"website\")[\"score\"].mean().sort_values(ascending=False)\n",
    "ranked_websites.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d1c28898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>similarity</th>\n",
       "      <th>website</th>\n",
       "      <th>average_position</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ</td>\n",
       "      <td>0.922499</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>3.909091</td>\n",
       "      <td>0.235988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ú¯Ø±Ø¯Ù†ÛŒ</td>\n",
       "      <td>0.912025</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.217149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯</td>\n",
       "      <td>0.915632</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.211300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø¨Ù„ÙˆØªÙˆØ«ÛŒ</td>\n",
       "      <td>0.912829</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>4.777778</td>\n",
       "      <td>0.191057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø¨ÛŒ Ø³ÛŒÙ…</td>\n",
       "      <td>0.915287</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>0.187751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ù…ÙˆØ¨Ø§ÛŒÙ„</td>\n",
       "      <td>0.912325</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>0.178015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ú¯ÙˆØ´ÛŒ</td>\n",
       "      <td>0.897348</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.172567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ù…Ø§Ù†ÛŒØªÙˆØ±</td>\n",
       "      <td>0.899764</td>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>0.131673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ú¯ÙˆØ´ÛŒ</td>\n",
       "      <td>0.897348</td>\n",
       "      <td>www.gsm.ir</td>\n",
       "      <td>37.666668</td>\n",
       "      <td>0.023823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ø¹Ú©Ø³ Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ</td>\n",
       "      <td>0.924241</td>\n",
       "      <td>ana.ir</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.017116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ù‚ÛŒÙ…Øª Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø§ÛŒÙÙˆÙ†</td>\n",
       "      <td>0.922936</td>\n",
       "      <td>www.gsm.ir</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.014199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ù‡Ø¯ÙÙˆÙ†</td>\n",
       "      <td>0.913788</td>\n",
       "      <td>zoomtech.org</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.011715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ø®Ø±ÛŒØ¯ ÙØ§Ù„ÙˆØ±</td>\n",
       "      <td>0.898237</td>\n",
       "      <td>www.gsm.ir</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.011228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ø¢ÛŒØ¯ÛŒ Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù…</td>\n",
       "      <td>0.896770</td>\n",
       "      <td>zoomlife.ir</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.011210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯</td>\n",
       "      <td>0.915632</td>\n",
       "      <td>www.gsm.ir</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.011166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ø¹Ú©Ø³ Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ</td>\n",
       "      <td>0.924241</td>\n",
       "      <td>www.gsm.ir</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.011135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø®Ø±ÛŒØ¯ Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø¨Ù„ÙˆØªÙˆØ«ÛŒ</td>\n",
       "      <td>0.924810</td>\n",
       "      <td>anzalweb.ir</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.010630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ø®Ø±ÛŒØ¯ Ù‡Ø¯ÙÙˆÙ†</td>\n",
       "      <td>0.913788</td>\n",
       "      <td>www.gsm.ir</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.010625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ù‚ÛŒÙ…Øª Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø¨Ù„ÙˆØªÙˆØ«ÛŒ</td>\n",
       "      <td>0.915900</td>\n",
       "      <td>www.gsm.ir</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.010528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø¢ÛŒÙÙˆÙ†</td>\n",
       "      <td>0.924234</td>\n",
       "      <td>www.gsm.ir</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.009627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         keyword  similarity        website  average_position  \\\n",
       "5                        Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ    0.922499  www.zoomit.ir          3.909091   \n",
       "14                 Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ú¯Ø±Ø¯Ù†ÛŒ    0.912025  www.zoomit.ir          4.200000   \n",
       "8                Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯    0.915632  www.zoomit.ir          4.333333   \n",
       "12               Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø¨Ù„ÙˆØªÙˆØ«ÛŒ    0.912829  www.zoomit.ir          4.777778   \n",
       "9                 Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø¨ÛŒ Ø³ÛŒÙ…    0.915287  www.zoomit.ir          4.875000   \n",
       "13                   Ø®Ø±ÛŒØ¯ Ù…ÙˆØ¨Ø§ÛŒÙ„    0.912325  www.zoomit.ir          5.125000   \n",
       "18                     Ø®Ø±ÛŒØ¯ Ú¯ÙˆØ´ÛŒ    0.897348  www.zoomit.ir          5.200000   \n",
       "15                  Ø®Ø±ÛŒØ¯ Ù…Ø§Ù†ÛŒØªÙˆØ±    0.899764  www.zoomit.ir          6.833333   \n",
       "17                     Ø®Ø±ÛŒØ¯ Ú¯ÙˆØ´ÛŒ    0.897348     www.gsm.ir         37.666668   \n",
       "1                    Ø¹Ú©Ø³ Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ    0.924241         ana.ir         54.000000   \n",
       "4             Ù‚ÛŒÙ…Øª Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø§ÛŒÙÙˆÙ†    0.922936     www.gsm.ir         65.000000   \n",
       "11                    Ø®Ø±ÛŒØ¯ Ù‡Ø¯ÙÙˆÙ†    0.913788   zoomtech.org         78.000000   \n",
       "16                    Ø®Ø±ÛŒØ¯ ÙØ§Ù„ÙˆØ±    0.898237     www.gsm.ir         80.000000   \n",
       "19          Ø®Ø±ÛŒØ¯ Ø¢ÛŒØ¯ÛŒ Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù…    0.896770    zoomlife.ir         80.000000   \n",
       "7                Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø³Ø§Ù…Ø³ÙˆÙ†Ú¯    0.915632     www.gsm.ir         82.000000   \n",
       "2                    Ø¹Ú©Ø³ Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ    0.924241     www.gsm.ir         83.000000   \n",
       "0   Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø®Ø±ÛŒØ¯ Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø¨Ù„ÙˆØªÙˆØ«ÛŒ    0.924810    anzalweb.ir         87.000000   \n",
       "10                    Ø®Ø±ÛŒØ¯ Ù‡Ø¯ÙÙˆÙ†    0.913788     www.gsm.ir         86.000000   \n",
       "6           Ù‚ÛŒÙ…Øª Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø¨Ù„ÙˆØªÙˆØ«ÛŒ    0.915900     www.gsm.ir         87.000000   \n",
       "3                  Ù‡Ù†Ø¯Ø²ÙØ±ÛŒ Ø¢ÛŒÙÙˆÙ†    0.924234     www.gsm.ir         96.000000   \n",
       "\n",
       "       score  \n",
       "5   0.235988  \n",
       "14  0.217149  \n",
       "8   0.211300  \n",
       "12  0.191057  \n",
       "9   0.187751  \n",
       "13  0.178015  \n",
       "18  0.172567  \n",
       "15  0.131673  \n",
       "17  0.023823  \n",
       "1   0.017116  \n",
       "4   0.014199  \n",
       "11  0.011715  \n",
       "16  0.011228  \n",
       "19  0.011210  \n",
       "7   0.011166  \n",
       "2   0.011135  \n",
       "0   0.010630  \n",
       "10  0.010625  \n",
       "6   0.010528  \n",
       "3   0.009627  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks.sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4f1c4705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "website\n",
       "anzalweb.ir            9.241214e-30\n",
       "www.gsm.ir             5.803781e-30\n",
       "www.zoomit.ir          1.005721e-30\n",
       "zoomtech.org           3.515494e-34\n",
       "digiato.com            1.008411e-38\n",
       "zoomlife.ir            8.112825e-40\n",
       "arzdigital.com         9.361835e-41\n",
       "www.fardanews.com      5.920407e-41\n",
       "jamejamonline.ir       3.788663e-41\n",
       "asemooni.com           5.250295e-42\n",
       "ana.ir                 2.161713e-42\n",
       "www.entekhab.ir        2.140458e-42\n",
       "www.sharghdaily.com    7.009531e-43\n",
       "mihanblockchain.com    5.854597e-44\n",
       "www.iranjib.ir         4.263496e-44\n",
       "www.tgju.org           5.425591e-45\n",
       "www.tabnak.ir          2.631182e-45\n",
       "techrato.com           7.516922e-46\n",
       "utofx.com              3.720903e-46\n",
       "footofan.com           2.195695e-46\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "result[\"score\"] = result[\"similarity\"] ** 768 / np.log(result[\"average_position\"] + 1)\n",
    "# Average of score per website\n",
    "ranked_websites = result.groupby(\"website\")[\"score\"].mean().sort_values(ascending=False)\n",
    "ranked_websites.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f172210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20mah\\AppData\\Local\\Temp\\ipykernel_19240\\1561052547.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  results.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'$defs': {'ScoredPoint': {'description': 'Search result',\n",
       "   'properties': {'id': {'anyOf': [{'type': 'integer'}, {'type': 'string'}],\n",
       "     'description': 'Search result',\n",
       "     'title': 'Id'},\n",
       "    'version': {'description': 'Point version',\n",
       "     'title': 'Version',\n",
       "     'type': 'integer'},\n",
       "    'score': {'description': 'Points vector distance to the query vector',\n",
       "     'title': 'Score',\n",
       "     'type': 'number'},\n",
       "    'payload': {'anyOf': [{'additionalProperties': True, 'type': 'object'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'description': 'Payload - values assigned to the point',\n",
       "     'title': 'Payload'},\n",
       "    'vector': {'anyOf': [{'items': {'type': 'number'}, 'type': 'array'},\n",
       "      {'items': {'items': {'type': 'number'}, 'type': 'array'},\n",
       "       'type': 'array'},\n",
       "      {'additionalProperties': {'anyOf': [{'items': {'type': 'number'},\n",
       "          'type': 'array'},\n",
       "         {'$ref': '#/$defs/SparseVector'},\n",
       "         {'items': {'items': {'type': 'number'}, 'type': 'array'},\n",
       "          'type': 'array'}]},\n",
       "       'type': 'object'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'description': 'Vector of the point',\n",
       "     'title': 'Vector'},\n",
       "    'shard_key': {'anyOf': [{'type': 'integer'},\n",
       "      {'type': 'string'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'description': 'Shard Key',\n",
       "     'title': 'Shard Key'},\n",
       "    'order_value': {'anyOf': [{'type': 'integer'},\n",
       "      {'type': 'number'},\n",
       "      {'type': 'null'}],\n",
       "     'default': None,\n",
       "     'description': 'Order-by value',\n",
       "     'title': 'Order Value'}},\n",
       "   'required': ['id', 'version', 'score'],\n",
       "   'title': 'ScoredPoint',\n",
       "   'type': 'object'},\n",
       "  'SparseVector': {'additionalProperties': False,\n",
       "   'description': 'Sparse vector structure',\n",
       "   'properties': {'indices': {'description': 'Indices must be unique',\n",
       "     'items': {'type': 'integer'},\n",
       "     'title': 'Indices',\n",
       "     'type': 'array'},\n",
       "    'values': {'description': 'Values and indices must be the same length',\n",
       "     'items': {'type': 'number'},\n",
       "     'title': 'Values',\n",
       "     'type': 'array'}},\n",
       "   'required': ['indices', 'values'],\n",
       "   'title': 'SparseVector',\n",
       "   'type': 'object'}},\n",
       " 'properties': {'points': {'description': '',\n",
       "   'items': {'$ref': '#/$defs/ScoredPoint'},\n",
       "   'title': 'Points',\n",
       "   'type': 'array'}},\n",
       " 'required': ['points'],\n",
       " 'title': 'QueryResponse',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd5818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0045,  0.0029,  0.0013,  ...,  0.0047, -0.0102,  0.0093])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for r in results.points:\n",
    "    # related_keywords.append(r.payload[\"text\"])\n",
    "    if \"website\" in r.payload:\n",
    "        print(f\"{r.score:<.4f} | {r.payload['website']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d4c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2500])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(average_position.array).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4c6ec8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2500, 1024])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_embedding.embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f2c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             keyword     score                 website  average_position\n",
      "0          Ø§ÛŒØ¯Ù‡ ØªÙˆÙ„Ø¯  0.946327          www.chetor.com          2.750000\n",
      "1              ØªÙˆØ­ÛŒØ¯  0.937184        www.beytoote.com          7.000000\n",
      "2         Ø³ÙˆØ±Ù‡ ØªÙˆØ­ÛŒØ¯  0.894493        www.beytoote.com          2.666667\n",
      "3         Ø³ÙˆØ±Ù‡ ØªÙˆØ­ÛŒØ¯  0.894493         www.delgarm.com         14.000000\n",
      "4       Ù…Ø§Ù‡ Ù‡Ø§ÛŒ ØªÙˆÙ„Ø¯  0.891508  www.tasvirezendegi.com          4.000000\n",
      "..               ...       ...                     ...               ...\n",
      "367  ØªÙˆÙ„Ø¯ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù‡Ø±  0.813686  www.tasvirezendegi.com          1.000000\n",
      "368     Ø§Ø­Ø§Ø¯ÛŒØ« Ú©ÙˆØªØ§Ù‡  0.813636                  ana.ir         52.000000\n",
      "369     Ø§Ø­Ø§Ø¯ÛŒØ« Ú©ÙˆØªØ§Ù‡  0.813636           www.talab.org          6.000000\n",
      "370     Ø´Ø§ÛŒÙ„ÛŒ Ù…Ø­Ù…ÙˆØ¯ÛŒ  0.813529            persianv.com         10.000000\n",
      "371     Ø´Ø§ÛŒÙ„ÛŒ Ù…Ø­Ù…ÙˆØ¯ÛŒ  0.813529       www.niksalehi.com          5.000000\n",
      "\n",
      "[372 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "debug_query = \"\"\"\n",
    "WITH\n",
    "    {keywords:Array(String)} AS keywords,\n",
    "    {scores:Array(Float32)} AS scores\n",
    "SELECT\n",
    "    q.keyword,\n",
    "    q.score,\n",
    "    d.website,\n",
    "    d.average_position\n",
    "FROM\n",
    "(\n",
    "    SELECT\n",
    "        arrayJoin(arrayEnumerate(keywords)) AS idx,\n",
    "        keywords[idx] AS keyword,\n",
    "        scores[idx] AS score\n",
    ") AS q\n",
    "LEFT OUTER JOIN\n",
    "(\n",
    "    SELECT\n",
    "        keyword,\n",
    "        website,\n",
    "        average_position\n",
    "    FROM ahrefs.keywords\n",
    ") AS d\n",
    "ON q.keyword = d.keyword\n",
    "\"\"\"\n",
    "\n",
    "result = [r.score for r in results.points]\n",
    "related_keywords = [r.payload[\"keyword\"] for r in results.points]\n",
    "\n",
    "websites = ch_client.query_df(\n",
    "    debug_query, parameters={\"keywords\": related_keywords, \"scores\": result}\n",
    ")\n",
    "print(websites)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0a41ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "      <th>weighted_avg_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.zoomit.ir</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.tgju.org</td>\n",
       "      <td>2.684793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>digiato.com</td>\n",
       "      <td>4.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arzdigital.com</td>\n",
       "      <td>6.445607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cryptonegar.com</td>\n",
       "      <td>6.734848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>www.kojaro.com</td>\n",
       "      <td>6.746941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>www.beytoote.com</td>\n",
       "      <td>6.893842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>safarpin.com</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>www.chetor.com</td>\n",
       "      <td>7.741090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>www.asriran.com</td>\n",
       "      <td>9.616824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>persianv.com</td>\n",
       "      <td>10.655098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>www.delgarm.com</td>\n",
       "      <td>10.705215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>www.tasvirezendegi.com</td>\n",
       "      <td>10.966324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>donya-e-eqtesad.com</td>\n",
       "      <td>12.022834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>www.tasnimnews.com</td>\n",
       "      <td>12.065790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>www.samatak.com</td>\n",
       "      <td>12.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>www.niksalehi.com</td>\n",
       "      <td>12.827004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>www.tabnak.ir</td>\n",
       "      <td>13.135743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>www.mashreghnews.ir</td>\n",
       "      <td>13.757428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dana.ir</td>\n",
       "      <td>22.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   website  weighted_avg_position\n",
       "0            www.zoomit.ir               1.000000\n",
       "1             www.tgju.org               2.684793\n",
       "2              digiato.com               4.406250\n",
       "3           arzdigital.com               6.445607\n",
       "4          cryptonegar.com               6.734848\n",
       "5           www.kojaro.com               6.746941\n",
       "6         www.beytoote.com               6.893842\n",
       "7             safarpin.com               7.000000\n",
       "8           www.chetor.com               7.741090\n",
       "9          www.asriran.com               9.616824\n",
       "10            persianv.com              10.655098\n",
       "11         www.delgarm.com              10.705215\n",
       "12  www.tasvirezendegi.com              10.966324\n",
       "13     donya-e-eqtesad.com              12.022834\n",
       "14      www.tasnimnews.com              12.065790\n",
       "15         www.samatak.com              12.190476\n",
       "16       www.niksalehi.com              12.827004\n",
       "17           www.tabnak.ir              13.135743\n",
       "18     www.mashreghnews.ir              13.757428\n",
       "19                 dana.ir              22.500000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    website,\n",
    "    sum(average_position * volume) / sum(volume) AS weighted_avg_position\n",
    "FROM ahrefs.keywords\n",
    "WHERE keyword IN {keywords:Array(String)}\n",
    "GROUP BY website\n",
    "ORDER BY weighted_avg_position ASC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "df = ch_client.query_df(query, parameters={\"keywords\": related_keywords})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b5783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seo-embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
